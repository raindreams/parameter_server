package PS;
// configuration of data, objective function, and optimizaiton method
import "proto/range.proto";

message AppConfig {
  enum AppType {
    RISK_MINIMIZATION = 1;
    SKETCH = 2;
  }
  optional AppType type = 1;
  optional string app_name = 2;
  repeated string parameter_name = 3;

  optional DataConfig training = 10;
  optional ParameterInitConfig init_w = 13;
  optional DataConfig model_output = 15;

  optional LossConfig loss = 20;
  optional PenaltyConfig penalty = 21;

  optional LearnerConfig learner = 30;

  optional BlockIteratorConfig block_iterator = 40;

  optional BlockCoordL1LRConfig block_coord_l1lr = 41;

  // optional GradDescConfig grad_desc = 21;
  // optional BlockProxGradConfig block_prox_grad = 22;
  // optional SketchConfig sketch = 31;
}

message DataConfig {
  enum DataFormat {
    BIN = 1;
    PROTO = 2;
    TEXT = 3;
  }
  required DataFormat format = 1;
  repeated string files = 2;
  optional PbRange range = 3;  // only valid for the binary format
}

message ParameterInitConfig {
  enum Type {
    ZERO = 1;
    RANDOM = 2;
    FILE = 3;
  }
  optional Type type = 1 [default = ZERO];
  optional double random_std = 2 [default = 1];
}

message BlockIteratorConfig {
  // the number of example in a block. It is the minibatch size for
  // minibatch-sgd. If <= 0, then use the whole data
  optional int64 example_block_size = 1 [default = -1];

  // divide a feature group into feature_block_ratio x nnz_feature_per_instance
  // blocks. If = 0, then use all features
  optional float feature_block_ratio = 2 [default = 0];

  // use a random order to updating feature block, it improves the
  // convergence. You may turn it off for debug use
  optional bool random_feature_block_order = 3 [default = true];

  optional int32 max_pass_of_data = 8 [default = 10];
  // bounded-delay consistency
  optional int32 max_block_delay = 10 [default = 0];

  // convergance critiria. stop if the relative objective <= epsilon
  optional double epsilon = 11 [default = 1e-4];

}

message BlockCoordL1LRConfig {
  optional double delta_init_value = 1 [default = 1];
  optional double delta_max_value = 2 [default = 5];
  // optional bool KKT_filter = 1 [default = true];

  // use multi-thread for calculation gradient and updating dual
  optional bool enable_multi_thread = 4 [default = false];

  // kkt_filter_threshold = max_gradient_violation / num_examples *
  // kkt_filter_threshold_ratio. increasing this number reduces the effect of
  // kkt filter.
  optional double kkt_filter_threshold_ratio = 10 [default = 10];

  optional int64 auc_goodness = 12 [default = 1000];
}

message LossConfig {
  enum Type {
    SQUARE = 1;
    LOGIT = 2;
    HINGE = 3;
    SQUARE_HINGE = 4;
  // SQUARE_SINGLE = 2;
  // LOGIT_SINGLE = 4;
  // HINGE_SINGLE = 6;
  }
  required Type type = 1;
}

message LearnerConfig {
  enum Type {
    GRADIENT_DESCENT = 1;
    PROXIMAL_GRADIENT = 2;
    LBFGS = 3;
  }
  required Type type = 1;
  optional float learning_rate = 2 [default = 1];
}


message AggGradLearnerArg {
  optional float learning_rate = 1 [default = 1];
}

message PenaltyConfig {
  enum Type {
    L1 = 1;
    L2 = 2;
  }
  required Type type = 1;
  required float coefficient = 2 [default = 0];
}
